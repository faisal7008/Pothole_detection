{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9L4fLBkRhQhp"
      },
      "source": [
        "# **YOLOv8 Small**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mGmQbAO5pQb"
      },
      "source": [
        "# Setup\n",
        "\n",
        "Pip install `ultralytics` and [dependencies](https://github.com/ultralytics/ultralytics/blob/main/requirements.txt) and check software and hardware."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wbvMlHd_QwMG",
        "outputId": "4a408ee2-87c4-47d4-9a21-3255ad08468e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ultralytics YOLOv8.0.92 ðŸš€ Python-3.10.11 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Setup complete âœ… (2 CPUs, 12.7 GB RAM, 23.4/78.2 GB disk)\n"
          ]
        }
      ],
      "source": [
        "%pip install ultralytics\n",
        "import ultralytics\n",
        "ultralytics.checks()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zhrq2q9CEE8x"
      },
      "source": [
        "## Mounting google drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HmxmGclznsYu"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3KH0BHhPD_wT"
      },
      "source": [
        "## Loading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_8OfXOSQnd66"
      },
      "outputs": [],
      "source": [
        "#Import the libraries\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "zip_ref = zipfile.ZipFile('/content/drive/MyDrive/Minor_Project_2/Pothole_dataset_final.zip', 'r') #Opens the zip file in read mode\n",
        "zip_ref.extractall('/content') #Extracts the files into the /tmp folder\n",
        "zip_ref.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0eq1SMWl6Sfn"
      },
      "source": [
        "# 1. Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1NcFxRcFdJ_O",
        "outputId": "ad6f08e1-a567-4e41-e8bf-23697072a783"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics YOLOv8.0.89 ðŸš€ Python-3.10.11 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1myolo/engine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8s.pt, data=/content/Pothole_dataset_final/pothole.yaml, epochs=100, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=/content/drive/MyDrive/Minor_Project_2/YOLOv8/small, name=None, exist_ok=False, pretrained=False, optimizer=SGD, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=0, resume=False, amp=True, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, line_thickness=3, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, v5loader=False, tracker=botsort.yaml, save_dir=/content/drive/MyDrive/Minor_Project_2/YOLOv8/small/train2\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       928  ultralytics.nn.modules.Conv                  [3, 32, 3, 2]                 \n",
            "  1                  -1  1     18560  ultralytics.nn.modules.Conv                  [32, 64, 3, 2]                \n",
            "  2                  -1  1     29056  ultralytics.nn.modules.C2f                   [64, 64, 1, True]             \n",
            "  3                  -1  1     73984  ultralytics.nn.modules.Conv                  [64, 128, 3, 2]               \n",
            "  4                  -1  2    197632  ultralytics.nn.modules.C2f                   [128, 128, 2, True]           \n",
            "  5                  -1  1    295424  ultralytics.nn.modules.Conv                  [128, 256, 3, 2]              \n",
            "  6                  -1  2    788480  ultralytics.nn.modules.C2f                   [256, 256, 2, True]           \n",
            "  7                  -1  1   1180672  ultralytics.nn.modules.Conv                  [256, 512, 3, 2]              \n",
            "  8                  -1  1   1838080  ultralytics.nn.modules.C2f                   [512, 512, 1, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.SPPF                  [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
            " 12                  -1  1    591360  ultralytics.nn.modules.C2f                   [768, 256, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
            " 15                  -1  1    148224  ultralytics.nn.modules.C2f                   [384, 128, 1]                 \n",
            " 16                  -1  1    147712  ultralytics.nn.modules.Conv                  [128, 128, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
            " 18                  -1  1    493056  ultralytics.nn.modules.C2f                   [384, 256, 1]                 \n",
            " 19                  -1  1    590336  ultralytics.nn.modules.Conv                  [256, 256, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
            " 21                  -1  1   1969152  ultralytics.nn.modules.C2f                   [768, 512, 1]                 \n",
            " 22        [15, 18, 21]  1   2116435  ultralytics.nn.modules.Detect                [1, [128, 256, 512]]          \n",
            "Model summary: 225 layers, 11135987 parameters, 11135971 gradients, 28.6 GFLOPs\n",
            "\n",
            "Transferred 349/355 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /content/drive/MyDrive/Minor_Project_2/YOLOv8/small/train2', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/Pothole_dataset_final/train/labels.cache... 2775 images, 0 backgrounds, 4 corrupt: 100% 2775/2775 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/Pothole_dataset_final/train/images/Pothole-261.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     5.5255      1.4888      2.2653      1.1414]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/Pothole_dataset_final/train/images/Pothole-262.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     6.3316      1.1216      3.1224      1.7171]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/Pothole_dataset_final/train/images/Pothole-268.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     5.2959      1.4144      1.1939]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/Pothole_dataset_final/train/images/Pothole-271.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     5.1327      1.5112       2.602]\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/Pothole_dataset_final/valid/labels.cache... 832 images, 0 backgrounds, 0 corrupt: 100% 832/832 [00:00<?, ?it/s]\n",
            "Plotting labels to /content/drive/MyDrive/Minor_Project_2/YOLOv8/small/train2/labels.jpg... \n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/drive/MyDrive/Minor_Project_2/YOLOv8/small/train2\u001b[0m\n",
            "Starting training for 100 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      1/100      3.93G      1.714      2.254      1.587         10        640: 100% 174/174 [08:09<00:00,  2.81s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 26/26 [01:09<00:00,  2.68s/it]\n",
            "                   all        832       2333      0.494       0.37      0.328      0.139\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      2/100      4.02G      1.556      1.395      1.408         13        640: 100% 174/174 [08:10<00:00,  2.82s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 26/26 [01:10<00:00,  2.73s/it]\n",
            "                   all        832       2333      0.498      0.354      0.338      0.136\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      3/100      4.02G      1.601       1.45      1.413         13        640: 100% 174/174 [08:06<00:00,  2.79s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 26/26 [01:13<00:00,  2.81s/it]\n",
            "                   all        832       2333      0.396      0.286      0.246      0.101\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      4/100      4.01G      1.654      1.511      1.463          8        640: 100% 174/174 [08:18<00:00,  2.86s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 26/26 [01:09<00:00,  2.67s/it]\n",
            "                   all        832       2333      0.405      0.298      0.274      0.115\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      5/100      4.02G       1.64      1.454      1.448         10        640: 100% 174/174 [08:21<00:00,  2.88s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 26/26 [01:11<00:00,  2.76s/it]\n",
            "                   all        832       2333      0.486      0.355      0.328      0.139\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      6/100      3.99G      1.613      1.422       1.45          9        640: 100% 174/174 [07:54<00:00,  2.73s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 26/26 [01:12<00:00,  2.77s/it]\n",
            "                   all        832       2333      0.449      0.358      0.336      0.138\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      7/100      3.98G      1.601      1.376      1.424         81        640:  91% 158/174 [07:07<00:38,  2.38s/it]"
          ]
        }
      ],
      "source": [
        "# Train the pothole dataset for 100 epochs using yolov8s pretrained model\n",
        "!yolo task=detect mode=train model=yolov8s.pt data=/content/Pothole_dataset_final/pothole.yaml epochs=100 imgsz=640 batch=16 project=/content/drive/MyDrive/Minor_Project_2/YOLOv8/small"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ub5F7T7o6Nh3",
        "outputId": "c95504e7-8eef-4c3d-d7f6-efd33747e072"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING âš ï¸ 'data' is missing. Using default 'data=coco128.yaml'.\n",
            "Ultralytics YOLOv8.0.91 ðŸš€ Python-3.10.11 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1myolo/engine/trainer: \u001b[0mtask=detect, mode=train, model=/content/drive/MyDrive/Minor_Project_2/YOLOv8/small/train2/weights/last.pt, data=/content/Pothole_dataset_final/pothole.yaml, epochs=100, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=/content/drive/MyDrive/Minor_Project_2/YOLOv8/small, name=None, exist_ok=False, pretrained=False, optimizer=SGD, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=0, resume=False, amp=True, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, line_thickness=3, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, v5loader=False, tracker=botsort.yaml, save_dir=/content/drive/MyDrive/Minor_Project_2/YOLOv8/small/train2\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n",
            "100% 755k/755k [00:00<00:00, 17.6MB/s]\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /content/drive/MyDrive/Minor_Project_2/YOLOv8/small/train2', view at http://localhost:6006/\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       928  ultralytics.nn.modules.Conv                  [3, 32, 3, 2]                 \n",
            "  1                  -1  1     18560  ultralytics.nn.modules.Conv                  [32, 64, 3, 2]                \n",
            "  2                  -1  1     29056  ultralytics.nn.modules.C2f                   [64, 64, 1, True]             \n",
            "  3                  -1  1     73984  ultralytics.nn.modules.Conv                  [64, 128, 3, 2]               \n",
            "  4                  -1  2    197632  ultralytics.nn.modules.C2f                   [128, 128, 2, True]           \n",
            "  5                  -1  1    295424  ultralytics.nn.modules.Conv                  [128, 256, 3, 2]              \n",
            "  6                  -1  2    788480  ultralytics.nn.modules.C2f                   [256, 256, 2, True]           \n",
            "  7                  -1  1   1180672  ultralytics.nn.modules.Conv                  [256, 512, 3, 2]              \n",
            "  8                  -1  1   1838080  ultralytics.nn.modules.C2f                   [512, 512, 1, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.SPPF                  [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
            " 12                  -1  1    591360  ultralytics.nn.modules.C2f                   [768, 256, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
            " 15                  -1  1    148224  ultralytics.nn.modules.C2f                   [384, 128, 1]                 \n",
            " 16                  -1  1    147712  ultralytics.nn.modules.Conv                  [128, 128, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
            " 18                  -1  1    493056  ultralytics.nn.modules.C2f                   [384, 256, 1]                 \n",
            " 19                  -1  1    590336  ultralytics.nn.modules.Conv                  [256, 256, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
            " 21                  -1  1   1969152  ultralytics.nn.modules.C2f                   [768, 512, 1]                 \n",
            " 22        [15, 18, 21]  1   2116435  ultralytics.nn.modules.Detect                [1, [128, 256, 512]]          \n",
            "Model summary: 225 layers, 11135987 parameters, 11135971 gradients, 28.6 GFLOPs\n",
            "\n",
            "Transferred 355/355 items from pretrained weights\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.pt to yolov8n.pt...\n",
            "100% 6.23M/6.23M [00:00<00:00, 82.6MB/s]\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/Pothole_dataset_final/train/labels... 2391 images, 0 backgrounds, 4 corrupt:  86% 2391/2775 [00:02<00:00, 1613.65it/s]/usr/local/lib/python3.10/dist-packages/PIL/TiffImagePlugin.py:625: UserWarning: Metadata Warning, tag 33723 had too many entries: 7, expected 1\n",
            "  warnings.warn(\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/Pothole_dataset_final/train/labels... 2775 images, 0 backgrounds, 4 corrupt: 100% 2775/2775 [00:02<00:00, 1134.82it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/Pothole_dataset_final/train/images/Pothole-261.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     5.5255      1.4888      2.2653      1.1414]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/Pothole_dataset_final/train/images/Pothole-262.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     6.3316      1.1216      3.1224      1.7171]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/Pothole_dataset_final/train/images/Pothole-268.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     5.2959      1.4144      1.1939]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/Pothole_dataset_final/train/images/Pothole-271.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     5.1327      1.5112       2.602]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/Pothole_dataset_final/train/labels.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/Pothole_dataset_final/valid/labels... 832 images, 0 backgrounds, 0 corrupt: 100% 832/832 [00:03<00:00, 274.70it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/Pothole_dataset_final/valid/labels.cache\n",
            "Plotting labels to /content/drive/MyDrive/Minor_Project_2/YOLOv8/small/train2/labels.jpg... \n",
            "Resuming training from /content/drive/MyDrive/Minor_Project_2/YOLOv8/small/train2/weights/last.pt from epoch 62 to 100 total epochs\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/drive/MyDrive/Minor_Project_2/YOLOv8/small/train2\u001b[0m\n",
            "Starting training for 100 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     62/100      3.97G     0.9485     0.6182      1.056         10        640: 100% 174/174 [07:48<00:00,  2.69s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 26/26 [01:10<00:00,  2.73s/it]\n",
            "                   all        832       2333      0.668       0.53      0.516      0.253\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     63/100      4.03G      0.934     0.5997      1.047         13        640: 100% 174/174 [08:00<00:00,  2.76s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 26/26 [01:05<00:00,  2.53s/it]\n",
            "                   all        832       2333      0.634      0.542      0.502      0.242\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     64/100      4.04G     0.9236     0.5968      1.045         13        640: 100% 174/174 [07:34<00:00,  2.61s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 26/26 [01:08<00:00,  2.62s/it]\n",
            "                   all        832       2333      0.631      0.531        0.5      0.244\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     65/100      4.02G      0.894     0.5779      1.035          8        640: 100% 174/174 [07:31<00:00,  2.60s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 26/26 [01:05<00:00,  2.53s/it]\n",
            "                   all        832       2333      0.666      0.533      0.514      0.249\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     66/100      4.02G     0.9087     0.5799      1.037         10        640: 100% 174/174 [07:54<00:00,  2.73s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 26/26 [01:07<00:00,  2.60s/it]\n",
            "                   all        832       2333      0.689      0.511      0.508      0.252\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     67/100         4G     0.8836     0.5677      1.027          9        640: 100% 174/174 [07:46<00:00,  2.68s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 26/26 [01:09<00:00,  2.68s/it]\n",
            "                   all        832       2333      0.663       0.53      0.518      0.256\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     68/100      3.99G     0.9071     0.5784      1.031          8        640: 100% 174/174 [07:54<00:00,  2.73s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 26/26 [01:07<00:00,  2.58s/it]\n",
            "                   all        832       2333       0.68      0.519      0.498      0.242\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     69/100      4.01G     0.9991     0.6392      1.077         13        640: 100% 174/174 [07:50<00:00,  2.71s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 26/26 [01:07<00:00,  2.61s/it]\n",
            "                   all        832       2333      0.666      0.534      0.522      0.259\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     70/100      3.99G      1.008     0.6484      1.082          7        640: 100% 174/174 [07:55<00:00,  2.73s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 26/26 [01:07<00:00,  2.60s/it]\n",
            "                   all        832       2333      0.682      0.523      0.523      0.257\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     71/100         4G     0.9704     0.6244      1.059         20        640: 100% 174/174 [07:45<00:00,  2.67s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 26/26 [01:08<00:00,  2.63s/it]\n",
            "                   all        832       2333      0.669      0.523       0.51      0.251\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     72/100      3.98G     0.9599     0.6155       1.06         11        640: 100% 174/174 [07:38<00:00,  2.64s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 26/26 [01:07<00:00,  2.59s/it]\n",
            "                   all        832       2333      0.679      0.527      0.518      0.256\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     73/100      3.99G     0.9523     0.6169      1.061         15        640: 100% 174/174 [07:47<00:00,  2.69s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 26/26 [01:09<00:00,  2.66s/it]\n",
            "                   all        832       2333      0.659      0.537      0.522      0.258\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     74/100      4.01G     0.9468     0.6044      1.048         10        640: 100% 174/174 [07:41<00:00,  2.65s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 26/26 [01:04<00:00,  2.50s/it]\n",
            "                   all        832       2333      0.669      0.529      0.517      0.256\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     75/100         4G     0.9396     0.5942      1.046         16        640: 100% 174/174 [07:44<00:00,  2.67s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 26/26 [01:05<00:00,  2.51s/it]\n",
            "                   all        832       2333      0.694      0.515      0.521      0.257\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     76/100      3.97G     0.9509     0.5967      1.053         11        640: 100% 174/174 [07:57<00:00,  2.75s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 26/26 [01:07<00:00,  2.60s/it]\n",
            "                   all        832       2333      0.675      0.534      0.522      0.259\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     77/100         4G     0.9362      0.601      1.042          4        640: 100% 174/174 [08:00<00:00,  2.76s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 26/26 [01:05<00:00,  2.52s/it]\n",
            "                   all        832       2333       0.67      0.534       0.52      0.261\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     78/100      3.98G     0.9167     0.5855      1.039          7        640: 100% 174/174 [07:43<00:00,  2.66s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 26/26 [01:08<00:00,  2.62s/it]\n",
            "                   all        832       2333      0.691      0.524      0.518      0.255\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     79/100      3.99G     0.9514     0.5963      1.057          7        640: 100% 174/174 [07:36<00:00,  2.63s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 26/26 [01:05<00:00,  2.50s/it]\n",
            "                   all        832       2333       0.67      0.539      0.524      0.259\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     80/100      3.99G     0.9457     0.6017       1.05         16        640: 100% 174/174 [07:54<00:00,  2.73s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 26/26 [01:06<00:00,  2.57s/it]\n",
            "                   all        832       2333      0.671       0.54      0.521      0.256\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     81/100      4.04G      0.922     0.5825      1.043          7        640: 100% 174/174 [07:51<00:00,  2.71s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 26/26 [01:04<00:00,  2.48s/it]\n",
            "                   all        832       2333      0.672      0.535      0.524      0.259\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     82/100      3.99G     0.9427     0.6052      1.032        109        640:   9% 16/174 [00:32<06:20,  2.41s/it]"
          ]
        }
      ],
      "source": [
        "# Resume the training\n",
        "!yolo task=detect mode=train resume=True model=/content/drive/MyDrive/Minor_Project_2/YOLOv8/small/train2/weights/last.pt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Validating the model"
      ],
      "metadata": {
        "id": "on7CfTMUIhQf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Validating YOLOv8 large model on Pothole dataset\n",
        "!yolo task=detect mode=val model=content/drive/MyDrive/Minor_Project_2/YOLOv8/small/train2/weights/last.pt line_thickness=1"
      ],
      "metadata": {
        "id": "uXw-8BMGIpWK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4JnkELT0cIJg"
      },
      "source": [
        "# 3. Predict\n",
        "\n",
        "YOLOv8 may be used directly in the Command Line Interface (CLI) with a `yolo` command for a variety of tasks and modes and accepts additional arguments, i.e. `imgsz=640`. See a full list of available `yolo` [arguments](https://docs.ultralytics.com/usage/cfg/) and other details in the [YOLOv8 Predict Docs](https://docs.ultralytics.com/modes/train/).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zR9ZbuQCH7FX",
        "outputId": "335d86e2-d717-4115-ef44-7bb89b7866f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics YOLOv8.0.78 ðŸš€ Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Model summary (fused): 168 layers, 3005843 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\n",
            "image 1/1 /content/Pothole_dataset/valid/images/G0028611.JPG: 480x640 1 pothole, 51.4ms\n",
            "Speed: 0.7ms preprocess, 51.4ms inference, 302.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/Minor_Project_2/YOLO/predict/predict\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# Run inference on an image with YOLOv8n\n",
        "!yolo predict model=/content/drive/MyDrive/Minor_Project_2/YOLO1/training/train5/weights/best.pt source='/content/Pothole_dataset/valid/images/G0028611.JPG' project=/content/drive/MyDrive/Minor_Project_2/YOLO/predict"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}